<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 4.8.0 for Hugo"><meta name=author content="Computer Graphics and Visualization Lab"><meta name=description content="We propose an end-to-end deep-learning approach for automatic rigging and retargeting of 3D models of human faces in the wild. Our approach, called Neural Face Rigging \(NFR\), holds three key properties\:<br>\(i\) NFR's expression space maintains human-interpretable editing parameters for artistic controls;<br>\(ii\) NFR is readily applicable to arbitrary facial meshes with different connectivity and expressions;<br>\(iii\) NFR can encode and produce fine-grained details of complex expressions performed by arbitrary subjects.<br>To the best of our knowledge, NFR is the first approach to provide realistic and controllable deformations of in-the-wild facial meshes, without the manual creation of blendshapes or correspondence. We design a deformation autoencoder and train it through a multi-dataset training scheme, which benefits from the unique advantages of two data sources\:a linear 3DMM with interpretable control parameters as in FACS, and 4D captures of real faces with fine-grained details. Through various experiments, we show NFR's ability to automatically produce realistic and accurate facial deformations across a wide range of existing datasets as well as noisy facial scans in-the-wild, while providing artist-controlled, editable parameters."><link rel=alternate hreflang=en-us href=/publication/nfr/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#2962ff"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/wowchemy.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu2e4579b938cb71ab526c5021d9215e0c_79015_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu2e4579b938cb71ab526c5021d9215e0c_79015_192x192_fill_lanczos_center_2.png><link rel=canonical href=/publication/nfr/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="HKU CGVU Lab"><meta property="og:url" content="/publication/nfr/"><meta property="og:title" content="Neural Face Rigging for Animating and Retargeting Facial Meshes in the Wild | HKU CGVU Lab"><meta property="og:description" content="We propose an end-to-end deep-learning approach for automatic rigging and retargeting of 3D models of human faces in the wild. Our approach, called Neural Face Rigging \(NFR\), holds three key properties\:<br>\(i\) NFR's expression space maintains human-interpretable editing parameters for artistic controls;<br>\(ii\) NFR is readily applicable to arbitrary facial meshes with different connectivity and expressions;<br>\(iii\) NFR can encode and produce fine-grained details of complex expressions performed by arbitrary subjects.<br>To the best of our knowledge, NFR is the first approach to provide realistic and controllable deformations of in-the-wild facial meshes, without the manual creation of blendshapes or correspondence. We design a deformation autoencoder and train it through a multi-dataset training scheme, which benefits from the unique advantages of two data sources\:a linear 3DMM with interpretable control parameters as in FACS, and 4D captures of real faces with fine-grained details. Through various experiments, we show NFR's ability to automatically produce realistic and accurate facial deformations across a wide range of existing datasets as well as noisy facial scans in-the-wild, while providing artist-controlled, editable parameters."><meta property="og:image" content="/publication/nfr/featured.jpg"><meta property="twitter:image" content="/publication/nfr/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2021-01-15T21:34:50+00:00"><meta property="article:modified_time" content="2021-01-15T21:34:50+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"/publication/nfr/"},"headline":"Neural Face Rigging for Animating and Retargeting Facial Meshes in the Wild","image":["/publication/nfr/featured.jpg"],"datePublished":"2021-01-15T21:34:50Z","dateModified":"2021-01-15T21:34:50Z","author":{"@type":"Person","name":"Dafei Qin"},"publisher":{"@type":"Organization","name":"HKU CGVU Lab","logo":{"@type":"ImageObject","url":"/images/logo_hu2e4579b938cb71ab526c5021d9215e0c_79015_192x192_fit_lanczos_2.png"}},"description":"We propose an end-to-end deep-learning approach for automatic rigging and retargeting of 3D models of human faces in the wild. Our approach, called Neural Face Rigging \\(NFR\\), holds three key properties\\:\u003cbr\u003e\\(i\\) NFR's expression space maintains human-interpretable editing parameters for artistic controls;\u003cbr\u003e\\(ii\\) NFR is readily applicable to arbitrary facial meshes with different connectivity and expressions;\u003cbr\u003e\\(iii\\) NFR can encode and produce fine-grained details of complex expressions performed by arbitrary subjects.\u003cbr\u003eTo the best of our knowledge, NFR is the first approach to provide realistic and controllable deformations of in-the-wild facial meshes, without the manual creation of blendshapes or correspondence. We design a deformation autoencoder and train it through a multi-dataset training scheme, which benefits from the unique advantages of two data sources\\:a linear 3DMM with interpretable control parameters as in FACS, and 4D captures of real faces with fine-grained details. Through various experiments, we show NFR's ability to automatically produce realistic and accurate facial deformations across a wide range of existing datasets as well as noisy facial scans in-the-wild, while providing artist-controlled, editable parameters."}</script><title>Neural Face Rigging for Animating and Retargeting Facial Meshes in the Wild | HKU CGVU Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><script>window.wcDarkLightEnabled=true;</script><script>const isSiteThemeDark=false;</script><script src=/js/load-theme.js></script><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/images/logo_hu2e4579b938cb71ab526c5021d9215e0c_79015_0x70_resize_lanczos_2.png alt="HKU CGVU Lab"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/images/logo_hu2e4579b938cb71ab526c5021d9215e0c_79015_0x70_resize_lanczos_2.png alt="HKU CGVU Lab"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class="nav-link active" href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/courses><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav><div class=pub><div class="article-container pt-3"><h1>Neural Face Rigging for Animating and Retargeting Facial Meshes in the Wild</h1><div class=article-metadata><div><span><a href=/author/dafei-qin/>Dafei Qin</a></span>, <span><a href=/author/jun-saito/>Jun Saito</a></span>, <span><a href=/author/noam-aigerman/>Noam Aigerman</a></span>, <span><a href=/author/thibault-groueix/>Thibault Groueix</a></span>, <span><a href=/author/taku-komura/>Taku Komura</a></span></div><span class=article-date>August 2023</span></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:366px><div style=position:relative><img src=/publication/nfr/featured_hu2218404e8519ab2e19fdec22a30847a3_1967057_720x0_resize_q90_lanczos.jpg alt class=featured-image></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>We propose an end-to-end deep-learning approach for automatic rigging and retargeting of 3D models of human faces in the wild. Our approach, called Neural Face Rigging (NFR), holds three key properties:<br>(i) NFR&rsquo;s expression space maintains human-interpretable editing parameters for artistic controls;<br>(ii) NFR is readily applicable to arbitrary facial meshes with different connectivity and expressions;<br>(iii) NFR can encode and produce fine-grained details of complex expressions performed by arbitrary subjects.<br>To the best of our knowledge, NFR is the first approach to provide realistic and controllable deformations of in-the-wild facial meshes, without the manual creation of blendshapes or correspondence. We design a deformation autoencoder and train it through a multi-dataset training scheme, which benefits from the unique advantages of two data sources:a linear 3DMM with interpretable control parameters as in FACS, and 4D captures of real faces with fine-grained details. Through various experiments, we show NFR&rsquo;s ability to automatically produce realistic and accurate facial deformations across a wide range of existing datasets as well as noisy facial scans in-the-wild, while providing artist-controlled, editable parameters.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#1>Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">SIGGRAPH 2023</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/facial-rigging/>Facial Rigging</a>
<a class="badge badge-light" href=/tag/facial-animation/>Facial Animation</a>
<a class="badge badge-light" href=/tag/retargeting/>Retargeting</a></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=/publication/nfr/&text=Neural%20Face%20Rigging%20for%20Animating%20and%20Retargeting%20Facial%20Meshes%20in%20the%20Wild" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=/publication/nfr/&t=Neural%20Face%20Rigging%20for%20Animating%20and%20Retargeting%20Facial%20Meshes%20in%20the%20Wild" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Neural%20Face%20Rigging%20for%20Animating%20and%20Retargeting%20Facial%20Meshes%20in%20the%20Wild&body=/publication/nfr/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=/publication/nfr/&title=Neural%20Face%20Rigging%20for%20Animating%20and%20Retargeting%20Facial%20Meshes%20in%20the%20Wild" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Neural%20Face%20Rigging%20for%20Animating%20and%20Retargeting%20Facial%20Meshes%20in%20the%20Wild%20/publication/nfr/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=/publication/nfr/&title=Neural%20Face%20Rigging%20for%20Animating%20and%20Retargeting%20Facial%20Meshes%20in%20the%20Wild" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/author/dafei-qin/><img class="avatar mr-3 avatar-circle" src=/author/dafei-qin/avatar_huc7eaf55a7a9d267e4b0828a780ebfe27_214218_270x270_fill_q90_lanczos_center.jpg alt="Dafei Qin"></a><div class=media-body><h5 class=card-title><a href=/author/dafei-qin/>Dafei Qin</a></h5><h6 class=card-subtitle>PhD, since Sep. 2020.</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:qindfei@connect.hku.hk><i class="fas fa-envelope"></i></a></li><li><a href=/dafei-qin.github.io><i class="fas fa-user-graduate"></i></a></li><li><a href=https://github.com/dafei-qin target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/author/taku-komura/><img class="avatar mr-3 avatar-circle" src=/author/taku-komura/avatar_hu13dcf3a41fad6ceb125ba13611db0352_110674_270x270_fill_q90_lanczos_center.jpg alt="Taku Komura"></a><div class=media-body><h5 class=card-title><a href=/author/taku-komura/>Taku Komura</a></h5><h6 class=card-subtitle>Professor</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:taku@cs.hku.hk><i class="fas fa-envelope"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/publication/bodyformer/>Bodyformer: Semantics-guided 3D Body Gesture Synthesis With Transformer</a></li><li><a href=/publication/tokenhsi-2025/>TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization</a></li><li><a href=/publication/dice-2025/>DICE: End-to-end Deformation Capture of Hand-Face Interactions from a Single Image</a></li><li><a href=/publication/cbil-2024/>CBIL: Collective Behavior Imitation Learning for Fish from Real Videos</a></li><li><a href=/publication/aarap-2024/>Analytic rotation-invariant modelling of anisotropic finite elements</a></li></ul></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script async defer src="https://maps.googleapis.com/maps/api/js?key=AIzaSyDRIRPRmqFRMGZ0_d60XJceM3MMWhGS1NQ%20%20"></script><script src=https://cdnjs.cloudflare.com/ajax/libs/gmaps.js/0.4.25/gmaps.min.js integrity="sha256-7vjlAeb8OaTrCXZkCNun9djzuB2owUsaO72kXaFDBJs=" crossorigin=anonymous></script><script>const code_highlighting=true;</script><script>const search_config={"indexURI":"/index.json","minLength":1,"threshold":0.3};const i18n={"no_results":"No results found","placeholder":"Search...","results":"results found"};const content_type={'post':"Posts",'project':"Projects",'publication':"Publications",'talk':"Talks",'slides':"Slides"};</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/wowchemy.min.4c2bca31150ce93c5a5e43b8a50f22fd.js></script><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by>Published with
<a href=https://wowchemy.com target=_blank rel=noopener>Wowchemy</a> —
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>